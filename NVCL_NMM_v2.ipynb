{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jia020/myJupyterNotebooks/blob/master/NVCL_NMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lleFy_-RZo1o"
      },
      "source": [
        "NMM(National Mineral Map) For NVCL datasets.\n",
        "NMM v2:\n",
        "Added analyticalService together in Notbook.\n",
        "Added countSum of mineral.\n",
        "Added borehole Depth.\n",
        "Added TSG file download link.\n",
        "Added Batch spectrum download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNtlwbkcDGZB"
      },
      "outputs": [],
      "source": [
        "pip install nvcl_kit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teYSx5jTog6a"
      },
      "outputs": [],
      "source": [
        "#import all libs for olivine\n",
        "import pandas as pd\n",
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "from folium.plugins import FastMarkerCluster\n",
        "from folium.plugins import BeautifyIcon\n",
        "from branca.element import Figure\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.set_option('display.width', 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnNxrXfCoh2N",
        "outputId": "cda3069d-0e25-4da5-e759-e3bc57f22af2"
      },
      "outputs": [],
      "source": [
        "#mount google drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#mineral = 'Pyroxene' #'Siderite'#'Pyroxene'#'Serpentine'#'Magnesite' #'Talc'#Olivine\n",
        "\n",
        "scalar ='Siderite'#'Magnesite'#'Siderite'#'Olivine'#'Pyroxene'#Talc#Fayalite or Olivine-Fe\n",
        "path=f'PathToData'\n",
        "mineral=scalar\n",
        "\n",
        "###############\n",
        "# algIDS is not version, but could map to version\n",
        "#VNIR group\n",
        "#algIDS=['83','97','8','21','27']\n",
        "\n",
        "#VNIR Mineral\n",
        "#algIDS=['82','96','7','20','26']\n",
        "\n",
        "#SWIR group\n",
        "#algIDS=['75','89','109','41','33','2','13','49']\n",
        "\n",
        "#SWIR Mineral\n",
        "#algIDS=['74','88','108','40','32','1','12','48']\n",
        "\n",
        "#TIR group\n",
        "#algIDS=['69','103','119','127','135','63','57','143']\n",
        "\n",
        "#TIR Mineral\n",
        "algIDS=['68','102','118','126','134','62','56','142']\n",
        "################\n",
        "\n",
        "fo = open(f'{path}/{scalar}-cellout.txt', 'a')\n",
        "def dual_print(f, *args, **kwargs):\n",
        "  print(*args, **kwargs)\n",
        "  print(*args, **kwargs, file=f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp6AlI3Axay6",
        "outputId": "09215c1d-eca7-4749-9f7c-fef265a05553"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from nvcl_kit.reader import NVCLReader\n",
        "from nvcl_kit.param_builder import param_builder\n",
        "import datetime\n",
        "\n",
        "readersDict =collections.defaultdict(lambda: collections.defaultdict(dict))\n",
        "statesList = ['nsw', 'tas', 'vic', 'qld', 'sa', 'wa', 'nt', 'csiro']\n",
        "print(f'startTime:{datetime.datetime.now().time()}')\n",
        "for state in statesList:\n",
        "  param = param_builder(state, bbox = { \"west\": 110, \"south\": -46, \"east\": 155, \"north\": -6 })#bbox for whole Australia\n",
        "  if not param:\n",
        "    print(f\"Cannot build parameters for {state}\")\n",
        "    break\n",
        "  reader = NVCLReader(param)\n",
        "  if not reader.wfs:\n",
        "    print(f\"No WFS for {state}\")\n",
        "    break\n",
        "  readersDict[state] = reader\n",
        "  dual_print(fo,f'{state}:{datetime.datetime.now().time()}')\n",
        "  fo.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uHH_w0Pu5UzR",
        "outputId": "a6f2d862-6a0d-4d6d-8f9c-2f8ae96e8b52"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "\n",
        "#get countSum for one borehole(nvcl_id)\n",
        "def getMineralCountSum (myReader,nvcl_id,mineral,myState):\n",
        "  dual_print(fo,f'start download spec for BH:{nvcl_id}')\n",
        "  logs_data_list = myReader.get_logs_data(nvcl_id)\n",
        "  scallist=[]\n",
        "  for ld in logs_data_list:\n",
        "    if ld.log_type == '1' and ld.algorithm_id in algIDS and ld.is_public=='true':\n",
        "      scallist.append(ld.log_id)\n",
        "  dual_print(fo,scallist)\n",
        "\n",
        "  countSum = 0\n",
        "  count = 0\n",
        "  for logid in scallist:\n",
        "    myInterval = 9999\n",
        "    if 'qld' in myState:\n",
        "      myInterval = 1\n",
        "    bh_data0 = myReader.get_sampled_scalar_data(logid,interval=myInterval)\n",
        "    buffer = StringIO(bh_data0.decode('utf-8'))\n",
        "    df0 = pd.read_csv(filepath_or_buffer = buffer)\n",
        "    df1=df0.loc[ df0.iloc[:,1].str.contains(mineral, na=False, case=False)]\n",
        "    #dual_print(df1)\n",
        "    if len(df1)==0:\n",
        "      count = 0\n",
        "    else:\n",
        "      count = df1['Count'].sum()\n",
        "    countSum += count\n",
        "  return countSum\n",
        "###############################\n",
        "#buildup new {mineral}-xy-scalar.csv\n",
        "#\tscalar\tState\tBoreholeName\tBoreholeURI\tLatitude\tLongitude\tValue\tLength\n",
        "mineral = scalar#Pyroxene'#'Serpentine'#'Siderite'#'Magnesite' #'Talc'#Olivine\n",
        "df = pd.read_csv(f'{path}/{mineral}-input.csv')\n",
        "dual_print(fo,f'{datetime.datetime.now().time()}:Input: df size is {len(df)}')\n",
        "\n",
        "dfW = pd.DataFrame(columns=['State',\t'BoreholeName',\t'BoreholeURI',\t'x',\t'y','countSum','Length','TsgLink'])\n",
        "\n",
        "cc=0\n",
        "scalarTest = 'fail'\n",
        "fScalar = float(-1.0)\n",
        "\n",
        "for row in df.itertuples():\n",
        "  myState = row.State\n",
        "  # if break somehow, you could continue on the index\n",
        "  # if (row.Index < 1931):\n",
        "  #   continue\n",
        "  nvcl_id = row.BoreholeURI.rsplit('/', 1)[-1]\n",
        "\n",
        "  fScalar = float(getMineralCountSum(readersDict[myState],nvcl_id,mineral,myState))\n",
        "  #x is lng(-180-180) y is Lat(-90-90)\n",
        "  dfW.loc[cc] = [row.State,row.BoreholeName,row.BoreholeURI,row.x,row.y,fScalar,row.Length,row.TsgLink]\n",
        "  dual_print(fo,f'{datetime.datetime.now().time()}:{mineral}:{cc}:{fScalar}:{row.BoreholeURI}')\n",
        "  fo.flush()\n",
        "  cc+=1\n",
        "#\n",
        "dual_print(fo,f'cc:{cc}')\n",
        "dfW.to_csv(f'{path}/{mineral}-xy-scalar.csv', index=False, sep=',', encoding='utf-8')\n",
        "fo.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEZXEfV3z5AQ",
        "outputId": "f7f2423a-a68f-49f9-e4f3-f46ac4e9e24a"
      },
      "outputs": [],
      "source": [
        "#show scalar on map\n",
        "#get lightness according countSum\n",
        "def scale_lightness(rgb, scale_l):\n",
        "  import colorsys\n",
        "  import matplotlib.colors as mc\n",
        "  # convert rgb to hls\n",
        "  h, l, s = colorsys.rgb_to_hls(*mc.to_rgb(rgb))\n",
        "  # manipulate h, l, s values and return as rgb\n",
        "  cT = colorsys.hls_to_rgb(h, min(1, l * scale_l), s = s)\n",
        "  return mc.rgb2hex(cT, keep_alpha=False)\n",
        "\n",
        "dfScalar=pd.read_csv(f'{path}/{mineral}-xy-scalar.csv')\n",
        "cx = dfScalar['x'].mean()\n",
        "cy = dfScalar['y'].mean()\n",
        "countSumMax=dfScalar['countSum'].max()\n",
        "countSumMean=dfScalar['countSum'].mean()\n",
        "fig2=Figure(width=1024,height=768)\n",
        "m2=folium.Map(location=[cy,cx],zoom_start=4)\n",
        "fig2.add_child(m2)\n",
        "# Add custom base maps to folium\n",
        "basemaps = {\n",
        "    'Google Maps': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Maps',overlay = False,control = True),\n",
        "    'Google Satellite': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Satellite',overlay = False,control = True),\n",
        "    'Google Terrain': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=p&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Terrain',overlay = False,control = True),\n",
        "    'Google Satellite Hybrid': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Satellite',overlay = False,control = True),\n",
        "    'Esri Satellite': folium.TileLayer(tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',attr = 'Esri',name = 'Esri Satellite',overlay = False,control = True)\n",
        "}\n",
        "basemaps['Google Satellite Hybrid'].add_to(m2)\n",
        "basemaps['Google Satellite'].add_to(m2)\n",
        "basemaps['Google Terrain'].add_to(m2)\n",
        "basemaps['Esri Satellite'].add_to(m2)\n",
        "basemaps['Google Maps'].add_to(m2)\n",
        "\n",
        "folium.LayerControl().add_to(m2)\n",
        "#add circle-dot for scalar boreholes:\n",
        "#blue(light vs dark) is pass the threshhold(countSumT)\n",
        "#red is fail\n",
        "cc=0\n",
        "countSumT = countSumMean#10000\n",
        "print(f'mineral:{mineral}:countSumMax:{countSumMax}:countSumMean:{countSumMean}')\n",
        "for row in dfScalar.itertuples():\n",
        "  if row.countSum > countSumT :\n",
        "    folium.Marker(location=[row.y,row.x],popup=f'{row.BoreholeName}--countSum:{row.countSum}--Depth:{row.Length}m\\n{row.BoreholeURI}\\n{row.TsgLink}',icon=BeautifyIcon(icon_shape='circle-dot', border_color=scale_lightness('#0000FF',float(row.countSum/countSumMax)*1.7), border_width=5,)).add_to(m2)\n",
        "  else:\n",
        "    folium.Marker(location=[row.y,row.x],popup=f'{row.BoreholeName}--countSum:{row.countSum}--Depth:{row.Length}m\\n{row.BoreholeURI}\\n{row.TsgLink}',icon=BeautifyIcon(icon_shape='circle-dot', border_color='red', border_width=5,)).add_to(m2)\n",
        "  cc+=1  \n",
        "m2.save(f'{path}/{mineral}-NMM-map.html')\n",
        "m2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4hG5ppxQFrI",
        "outputId": "81eb7daa-de21-4b4f-9c98-c171cab2631f"
      },
      "outputs": [],
      "source": [
        "#Batch downloading scalar spec data as csv for boreholes nvcl_id\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "from io import StringIO\n",
        "import os\n",
        "import array\n",
        "fo = open(f'{path}/{mineral}-spec-cellout.txt', 'a')\n",
        "def dual_print(f, *args, **kwargs):\n",
        "  print(*args, **kwargs)\n",
        "  print(*args, **kwargs, file=f)\n",
        "#############################\n",
        "specNumLimit = 10\n",
        "specGapMeters = 5\n",
        "specNumLimitBH = 3\n",
        "#build up top scalar countSum bhList for download Spectrum later.\n",
        "dfScalar=pd.read_csv(f'{path}/{mineral}-xy-scalar.csv')\n",
        "dfScalar2Download = dfScalar.sort_values(by=['countSum'], ascending=False)\n",
        "countBH = 0\n",
        "dual_print(fo, f'Reading:{path}/{mineral}-xy-scalar.csv')\n",
        "for row in dfScalar2Download.itertuples():\n",
        "  nvcl_id = row.BoreholeURI.rsplit('/', 1)[-1]\n",
        "  myState = row.State\n",
        "  if ('sa' in myState): #SA is really slow, skip it for the moment.\n",
        "    continue\n",
        "  if (myState not in readersDict):\n",
        "    dual_print(fo, f'{myState}not in readersDict')\n",
        "    continue\n",
        "  dual_print(fo, f'{myState}:{nvcl_id}:start download spec:')\n",
        "  myReader = readersDict[myState]\n",
        "  logs_data_list = myReader.get_logs_data(nvcl_id)\n",
        "  scallist=[]\n",
        "  for ld in logs_data_list:\n",
        "    if ld.log_type == '1' and ld.algorithm_id in algIDS and ld.is_public=='true':\n",
        "      scallist.append(ld.log_id)\n",
        "  dual_print(fo, scallist)\n",
        "  bh_data = myReader.get_scalar_data(scallist)\n",
        "  buffer = StringIO(bh_data.decode('utf-8'))\n",
        "  df = pd.read_csv(filepath_or_buffer = buffer)\n",
        "  dfS=df.loc[ (df.iloc[:,2].str.contains(mineral, na=False, case=False)) | (df.iloc[:,3].str.contains(mineral, na=False, case=False)) | (df.iloc[:,4].str.contains(mineral, na=False, case=False)) ]\n",
        "  if len(dfS) < 2:\n",
        "    dual_print(fo, dfS)\n",
        "    dual_print(fo, f'BAD:no scalar[ {mineral}] in database')\n",
        "    ####################################################################\n",
        "  else:\n",
        "    speclogs = myReader.get_spectrallog_data(nvcl_id)\n",
        "    dfSS = dfS\n",
        "    cc = 0\n",
        "    previousDepth = 0\n",
        "    for index, row in dfS.iterrows():\n",
        "      if (row.StartDepth - previousDepth) < specGapMeters:\n",
        "        continue # 1 spec per specGapMeters\n",
        "      previousDepth = row.StartDepth\n",
        "      cc += 1\n",
        "      if cc > specNumLimit: # max spec from a BH\n",
        "        dual_print(fo, f'outOfLimit:{cc}')\n",
        "        break\n",
        "      for speclog in speclogs:\n",
        "        if speclog.sample_count > 0:\n",
        "          wvName=f'WV-{speclog.wavelengths[0]}-{speclog.wavelengths[1]-speclog.wavelengths[0]}-{speclog.wavelengths[-1]}'.replace('.','_')\n",
        "          if wvName not in dfSS.columns:\n",
        "            dfSS[wvName] = ''\n",
        "          spec_data=myReader.get_spectrallog_datasets(speclog.log_id,start_sample_no=index,end_sample_no=index)\n",
        "          U = array.array(\"f\")\n",
        "          U.frombytes(spec_data)\n",
        "          spec_dataS=\",\".join(map(str, U))\n",
        "          dfSS.loc[index,wvName] = spec_dataS\n",
        "\n",
        "    #save the raw spectrum into file\n",
        "          \n",
        "    dfSS.to_csv(f'{path}/{mineral}-spec-{myState}-{nvcl_id}.csv', index=False, sep=',', encoding='utf-8')\n",
        "    dual_print(fo, f'{path}/{mineral}-spec-{myState}-{nvcl_id}.csv')\n",
        "    dual_print(fo, f'{datetime.datetime.now().time()}:{myState}:{nvcl_id}:specNumLimit:{specNumLimit}:specGapMeters:{specGapMeters}:total specs:{len(dfSS)}')\n",
        "    fo.flush()\n",
        "#########for BH\n",
        "  if countBH >= specNumLimitBH: #we only download  spec for limited boreholes(specNumLimitBH)\n",
        "    break\n",
        "  countBH+=1  \n",
        "fo.close()  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DIVLQT873Ps"
      },
      "outputs": [],
      "source": [
        "#Plot the spectrum chart for one borehole(etc:Magnesite-spec-sa-1575.csv)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "#load spectrum from file\n",
        "\n",
        "nvcl_id = '75003'\n",
        "myState = 'qld'\n",
        "dfSS = pd.read_csv(f'{path}/{mineral}-spec-{myState}-{nvcl_id}.csv') # #Magnesite-spec-nsw-MIN_003428.csv #Olivine-spec-nsw-MIN_003446.csv #Olivine-spec-sa-241830.csv #Pyroxene-spec-wa-SMD164.csv #Siderite-spec-wa-KPDDH008.csv\n",
        "dfSS.replace('', np.nan, inplace=True)\n",
        "dfSS.dropna(inplace = True)\n",
        "print(dfSS)\n",
        "#buildup wvLengths array from column name\n",
        "wv1 = dfSS.columns[-1]\n",
        "wv11 = wv1.split('-')\n",
        "wv1Start = float(wv11[1].replace('_','.'))\n",
        "wv1Step= float(wv11[2].replace('_','.'))\n",
        "wv1End = float(wv11[3].replace('_','.'))\n",
        "wv1Lengths = np.arange(wv1Start, wv1End+wv1Step,wv1Step,dtype=float)\n",
        "\n",
        "wv2 = dfSS.columns[-2]\n",
        "wv22 = wv2.split('-')\n",
        "wv2Start = float(wv22[1].replace('_','.'))\n",
        "wv2Step= float(wv22[2].replace('_','.'))\n",
        "wv2End = float(wv22[3].replace('_','.'))\n",
        "wv2Lengths = np.arange(wv2Start, wv2End+wv2Step,wv2Step,dtype=float)\n",
        "#init a empty dataframe\n",
        "cnames=['wvLengths']\n",
        "df1 = pd.DataFrame(columns=cnames)\n",
        "df1['wvLengths'] = wv1Lengths\n",
        "df2= pd.DataFrame(columns=cnames)\n",
        "df2['wvLengths'] = wv2Lengths\n",
        "#fillup the spec column into dataframe\n",
        "indexList = [0,5]\n",
        "for index, row in dfSS.iterrows():\n",
        "  # if index not in indexList: #611: #If I want a specific row\n",
        "  #   continue\n",
        "  specName = f'spec{index}'\n",
        "  spec1 = np.array(row[wv1].split(','),dtype=np.float32)\n",
        "  spec2 = np.array(row[wv2].split(','),dtype=np.float32)\n",
        "  df1[specName] = spec1\n",
        "  df2[specName] = spec2\n",
        "#plot all specs\n",
        "fig,ax = plt.subplots()\n",
        "for i, col in enumerate(df1.columns):\n",
        "  if col == 'wvLengths':\n",
        "    continue\n",
        "  myLabel = 'depth:'+ str(dfSS.loc[i-1,'StartDepth'])\n",
        "  ax.plot(df1['wvLengths'],df1[col],label= myLabel)\n",
        "plt.legend(loc=\"upper left\")  \n",
        "plt.savefig(f'{path}/{mineral}-spec-{nvcl_id}-TIR.png')\n",
        "\n",
        "fig1,ax1 = plt.subplots()\n",
        "for i, col in enumerate(df2.columns):\n",
        "  if col == 'wvLengths':\n",
        "    continue\n",
        "  myLabel = 'depth:'+ str(dfSS.loc[i-1,'StartDepth'])\n",
        "  ax1.plot(df2['wvLengths'],df2[col],label= myLabel)\n",
        "plt.legend(loc=\"upper right\") \n",
        "plt.savefig(f'{path}/{mineral}-spec-{nvcl_id}-SWIR.png')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Single Download scalar spec data as csv for borehole nvcl_id\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "import io\n",
        "import array\n",
        "\n",
        "#pass,tas,ML048,http://www.mrt.tas.gov.au/resource/feature/mrt/borehole/10350,-41.69823623,145.32070134\n",
        "#pass,tas,Forest-1,http://www.mrt.tas.gov.au/resource/feature/mrt/borehole/6200,-40.8151763,145.25523887\n",
        "\n",
        "# Log name has 2 parts:\n",
        "# 1. Min1,2,3 = 1st, 2nd, 3rd most common mineral\n",
        "#    OR Grp1,2,3 = 1st, 2nd, 3rd most common group of minerals\n",
        "# 2. uTSAV = visible light, uTSAS = shortwave IR, uTSAT = thermal IR\n",
        "#\n",
        "# These combine to give us a class name such as 'Grp1 uTSAS'\n",
        "#\n",
        "# Here we extract data for log type '1' and log name 'Grp1 uTSAS'\n",
        "#Siderite-spec-wa-KPDDH008.csv\n",
        "myState = 'qld'\n",
        "reader = readersDict[myState]\n",
        "nvcl_id = '75003' #KSDD006'\n",
        "print(f'start download spec for BH:{nvcl_id}')\n",
        "\n",
        "\n",
        "logs_data_list = reader.get_logs_data(nvcl_id)\n",
        "scallist=[]\n",
        "for ld in logs_data_list:\n",
        "  if ld.log_type == '1' and ld.algorithm_id in algIDS and ld.is_public=='true':\n",
        "    scallist.append(ld.log_id)\n",
        "print(scallist)\n",
        "bh_data = reader.get_scalar_data(scallist)\n",
        "print(f'bh_data:{len(bh_data)}')\n",
        "buffer = io.StringIO(bh_data.decode('utf-8'))\n",
        "df = pd.read_csv(filepath_or_buffer = buffer)\n",
        "dfS=df.loc[ (df.iloc[:,2].str.contains(scalar, na=False, case=False)) | (df.iloc[:,3].str.contains(scalar, na=False, case=False)) | (df.iloc[:,4].str.contains(scalar, na=False, case=False)) ]\n",
        "cc =0\n",
        "#dfS=df.loc[ (df.iloc[:,2] == scalar) | (df.iloc[:,3] == scalar) | (df.iloc[:,4] == scalar) ]\n",
        "if len(dfS) < 2:\n",
        "  print(dfS)\n",
        "  print('BAD:no scalar in database')\n",
        "else:\n",
        "  ####################################################################\n",
        "  speclogs = reader.get_spectrallog_data(nvcl_id)\n",
        "  dfSS = dfS\n",
        "  for index, row in dfS.iterrows():\n",
        "    if (cc>10): # otherwise take too long to download all the spectrums\n",
        "      break\n",
        "    for speclog in speclogs:\n",
        "      if speclog.sample_count > 0:\n",
        "        wvName=f'WV-{speclog.wavelengths[0]}-{speclog.wavelengths[1]-speclog.wavelengths[0]}-{speclog.wavelengths[-1]}'.replace('.','_')\n",
        "        if wvName not in dfSS.columns:\n",
        "          dfSS[wvName] = ''\n",
        "        spec_data=reader.get_spectrallog_datasets(speclog.log_id,start_sample_no=index,end_sample_no=index)\n",
        "        U = array.array(\"f\")\n",
        "        U.frombytes(spec_data)\n",
        "        spec_dataS=\",\".join(map(str, U))\n",
        "        dfSS.loc[index,wvName] = spec_dataS\n",
        "        cc +=1\n",
        "\n",
        "  #save the raw spectrum into file\n",
        "  dfSS.to_csv(f'{path}/{mineral}-spec-{myState}-{nvcl_id}.csv', index=False, sep=',', encoding='utf-8')\n",
        "  print(f'total specs:{len(dfSS)}')\n",
        "  print(dfSS.head(5))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
