{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jia020/myJupyterNotebooks/blob/master/NVCL_NMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NMM(National Mineral Map) For NVCL datasets."
      ],
      "metadata": {
        "id": "lleFy_-RZo1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nvcl_kit"
      ],
      "metadata": {
        "id": "bNtlwbkcDGZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "teYSx5jTog6a"
      },
      "outputs": [],
      "source": [
        "#import all libs for olivine\n",
        "import pandas as pd\n",
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "from folium.plugins import FastMarkerCluster\n",
        "from folium.plugins import BeautifyIcon\n",
        "from branca.element import Figure\n",
        "\n",
        "pd.options.mode.chained_assignment = None\n",
        "pd.set_option('display.width', 400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WnNxrXfCoh2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b5032e-2475-4f0f-ac04-95bf7ce5888f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "scalar ='Fayalite'\n",
        "path=f'/content/drive/My Drive/work/{scalar}/'\n",
        "analyticalFileList = ['passIds.csv','failIds.csv','errorIds.csv','passIds0.csv','failIds0.csv','errorIds0.csv']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKQNE3g_AjKz"
      },
      "outputs": [],
      "source": [
        "#build xy-state.csv for each state, NT take really long time.\n",
        "#If you aleady  have file xy-all-5645.csv, you could skip this code cell.\n",
        "from nvcl_kit.reader import NVCLReader\n",
        "from nvcl_kit.param_builder import param_builder\n",
        "xy_dict = {}\n",
        "statesList = ['nsw', 'tas', 'vic', 'qld', 'nt', 'sa', 'wa', 'csiro']\n",
        "for state in statesList:\n",
        "  param = param_builder(state, bbox = { \"west\": 110, \"south\": -46, \"east\": 155, \"north\": -6 })#bbox for whole Australia\n",
        "  if not param:\n",
        "    print(f\"Cannot build parameters for {state}\")\n",
        "    break\n",
        "  reader = NVCLReader(param)\n",
        "  if not reader.wfs:\n",
        "    print(f\"No WFS for {state}\")\n",
        "    break\n",
        "  bh_list = reader.get_boreholes_list()\n",
        "  dfW = pd.DataFrame(bh_list, columns=['href', 'x','y','name','state']) #.sample(n=500)\n",
        "  dfW['state'] = state\n",
        "  num = dfW.shape[0]\n",
        "  dfW.to_csv(f'{path}xy-{state}.csv', sep=',', encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#buildup xy-all-5645.csv\n",
        "#If you aleady  have file xy-all-5645.csv, you could skip this code cell.\n",
        "\n",
        "statesList = ['nsw', 'tas', 'vic', 'qld', 'nt', 'sa', 'wa', 'csiro']\n",
        "\n",
        "df0 = pd.DataFrame(columns=['href', 'x','y','name','state'])\n",
        "for state in statesList:\n",
        "  df1 = pd.read_csv(f'{path}xy-{state}.csv')\n",
        "  df0 = pd.merge(df0[['href', 'x','y','name','state']], df1[['href', 'x','y','name','state']],  how = \"outer\")\n",
        "  num = df0.shape[0]\n",
        "  print(f'{num}')\n",
        "dfW.to_csv(f'{path}xy-all-5645.csv', sep=',', encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "A4QdyLVIRIP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#buildup olivine.csv (merge from error.csv + fail.csv + pass.csv)\n",
        "#fileList = ['passIds.csv','failIds.csv','errorIds.csv','passIds0.csv','failIds0.csv','errorIds0.csv']\n",
        "li = []\n",
        "for file in analyticalFileList:\n",
        "  try:\n",
        "    df5 = pd.read_csv(f'{path}{file}',names = ['BoreholeURI','scalar'], index_col=False, sep=',')\n",
        "    li.append(df5)\n",
        "  except pd.errors.EmptyDataError:\n",
        "    print(f'{path}{file} is empty')\n",
        "\n",
        "df5 = pd.concat(li, axis=0, ignore_index=True)\n",
        "dframe = df5[['BoreholeURI','scalar']]\n",
        "dframe.to_csv(f'{path}scalar.csv',index=False,sep=',', encoding='utf-8')"
      ],
      "metadata": {
        "id": "CUZTL3nDcgiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF-2OaulPaQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3657faff-4fc3-4d0b-a01a-c76464e70487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xy_dict size is 5645\n",
            "p:12,f:1272,e:4213,t:5497\n"
          ]
        }
      ],
      "source": [
        "#buildup xy-olivine.csv\n",
        "df = pd.read_csv(f'{path}scalar.csv')\n",
        "xy_dict = pd.read_csv(f'{path}xy-all-5645.csv').set_index('href').to_dict(orient='index')\n",
        "print(f'xy_dict size is {len(xy_dict)}')\n",
        "\n",
        "dfW = pd.DataFrame(columns=['scalar', 'State',\t'BoreholeName',\t'BoreholeURI',\t'Latitude',\t'Longitude'])\n",
        "\n",
        "t=0\n",
        "p=0\n",
        "f=0\n",
        "e=0\n",
        "scalarTest = 'fail'\n",
        "for row in df.itertuples():\n",
        "  if(row.scalar.find('Hit:')>=0):\n",
        "    scalarTest='pass'\n",
        "    p+=1\n",
        "  elif(row.scalar.find('Miss:')>=0):\n",
        "    scalarTest='fail'\n",
        "    f+=1\n",
        "  else:\n",
        "    scalarTest='error'\n",
        "    e+=1\n",
        "  dfW.loc[t] = [scalarTest,xy_dict[row.BoreholeURI]['state'],xy_dict[row.BoreholeURI]['name'],row.BoreholeURI,xy_dict[row.BoreholeURI]['y'],xy_dict[row.BoreholeURI]['x']]\n",
        "  t+=1\n",
        "#\n",
        "print(f'p:{p},f:{f},e:{e},t:{t}')\n",
        "dfW.to_csv(f'{path}xy-scalar.csv', index=False, sep=',', encoding='utf-8')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxk1a79Q2OwQ"
      },
      "outputs": [],
      "source": [
        "#show scalar on map\n",
        "dfScalar=pd.read_csv(f'{path}xy-scalar.csv')\n",
        "#[['scalar', 'State',\t'BoreholeName',\t'BoreholeURI',\t'Latitude',\t'Longitude']]\n",
        "cx = dfScalar['Longitude'].mean()\n",
        "cy = dfScalar['Latitude'].mean()\n",
        "fig2=Figure(width=1024,height=768)\n",
        "m2=folium.Map(location=[cy,cx],zoom_start=4)\n",
        "fig2.add_child(m2)\n",
        "# Add custom base maps to folium\n",
        "basemaps = {\n",
        "    'Google Maps': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Maps',overlay = False,control = True),\n",
        "    'Google Satellite': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Satellite',overlay = False,control = True),\n",
        "    'Google Terrain': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=p&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Terrain',overlay = False,control = True),\n",
        "    'Google Satellite Hybrid': folium.TileLayer(tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',attr = 'Google',name = 'Google Satellite',overlay = False,control = True),\n",
        "    'Esri Satellite': folium.TileLayer(tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',attr = 'Esri',name = 'Esri Satellite',overlay = False,control = True)\n",
        "}\n",
        "basemaps['Google Maps'].add_to(m2)\n",
        "basemaps['Google Satellite Hybrid'].add_to(m2)\n",
        "basemaps['Google Satellite'].add_to(m2)\n",
        "basemaps['Google Terrain'].add_to(m2)\n",
        "basemaps['Esri Satellite'].add_to(m2)\n",
        "folium.LayerControl().add_to(m2)\n",
        "#add circle-dot for scalar boreholes:\n",
        "#blue is pass\n",
        "#red is fail\n",
        "#yellow is error\n",
        "cc=0\n",
        "for row in dfScalar.itertuples():\n",
        "  if row.scalar == 'pass' :\n",
        "    folium.Marker(location=[row.Latitude,row.Longitude],popup=row.BoreholeName,icon=BeautifyIcon(icon_shape='circle-dot', border_color='blue', border_width=3,)).add_to(m2)\n",
        "  elif row.scalar == 'fail':\n",
        "    folium.Marker(location=[row.Latitude,row.Longitude],popup=row.BoreholeName,icon=BeautifyIcon(icon_shape='circle-dot', border_color='red', border_width=3,)).add_to(m2)\n",
        "    cc = cc\n",
        "  else:\n",
        "    folium.Marker(location=[row.Latitude,row.Longitude],popup=row.BoreholeName,icon=BeautifyIcon(icon_shape='circle-dot', border_color='yellow', border_width=3,)).add_to(m2)\n",
        "    cc = cc\n",
        "  cc+=1\n",
        "m2.save(f'{path}scalar-au-map.html')\n",
        "m2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nvcl_kit.reader import NVCLReader\n",
        "from nvcl_kit.param_builder import param_builder\n",
        "xy_dict = {}\n",
        "statesList = ['tas'] #['nsw', 'tas', 'vic', 'qld', 'nt', 'sa', 'wa', 'csiro']\n",
        "for state in statesList:\n",
        "  param = param_builder(state, bbox = { \"west\": 110, \"south\": -46, \"east\": 155, \"north\": -6 })#bbox for whole Australia\n",
        "  if not param:\n",
        "    print(f\"Cannot build parameters for {state}\")\n",
        "    break\n",
        "  reader = NVCLReader(param)\n",
        "  if not reader.wfs:\n",
        "    print(f\"No WFS for {state}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "OBieTzHwKNt8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download scalar spec data as csv for borehole nvcl_id\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "import io\n",
        "import array\n",
        "nvcl_id = '6200'#'10350'\n",
        "\n",
        "#pass,tas,ML048,http://www.mrt.tas.gov.au/resource/feature/mrt/borehole/10350,-41.69823623,145.32070134\n",
        "#pass,tas,Forest-1,http://www.mrt.tas.gov.au/resource/feature/mrt/borehole/6200,-40.8151763,145.25523887\n",
        "\n",
        "#SWIR group\n",
        "#algIDS=['75','89','109','41','33','2','13','49']\n",
        "\n",
        "#SWIR Mineral\n",
        "#algIDS=['74','88','108','40','32','1','12','48']\n",
        "\n",
        "#TIR group\n",
        "#algIDS=['69','103','119','127','135','63','57','143']\n",
        "\n",
        "#TIR Mineral\n",
        "algIDS=['68','102','118','126','134','62','56','142']\n",
        "\n",
        "# Log name has 2 parts:\n",
        "# 1. Min1,2,3 = 1st, 2nd, 3rd most common mineral\n",
        "#    OR Grp1,2,3 = 1st, 2nd, 3rd most common group of minerals\n",
        "# 2. uTSAV = visible light, uTSAS = shortwave IR, uTSAT = thermal IR\n",
        "#\n",
        "# These combine to give us a class name such as 'Grp1 uTSAS'\n",
        "#\n",
        "# Here we extract data for log type '1' and log name 'Grp1 uTSAS'\n",
        "print(f'start download spec for BH:{nvcl_id}')\n",
        "logs_data_list = reader.get_logs_data(nvcl_id)\n",
        "scallist=[]\n",
        "for ld in logs_data_list:\n",
        "  if ld.log_type == '1' and ld.algorithm_id in algIDS and ld.is_public=='true':\n",
        "    scallist.append(ld.log_id)\n",
        "\n",
        "bh_data = reader.get_scalar_data(scallist)\n",
        "buffer = io.StringIO(bh_data.decode('utf-8'))\n",
        "df = pd.read_csv(filepath_or_buffer = buffer)\n",
        "dfS=df.loc[ (df.iloc[:,2] == scalar) | (df.iloc[:,3] == scalar) | (df.iloc[:,4] == scalar) ]\n",
        "\n",
        "####################################################################\n",
        "speclogs = reader.get_spectrallog_data(nvcl_id)\n",
        "dfSS = dfS\n",
        "for index, row in dfS.iterrows():\n",
        "  for speclog in speclogs:\n",
        "    if speclog.sample_count > 0:\n",
        "      wvName=f'WV-{speclog.wavelengths[0]}-{speclog.wavelengths[1]-speclog.wavelengths[0]}-{speclog.wavelengths[-1]}'.replace('.','_')\n",
        "      if wvName not in dfSS.columns:\n",
        "        dfSS[wvName] = ''\n",
        "      spec_data=reader.get_spectrallog_datasets(speclog.log_id,start_sample_no=index,end_sample_no=index)\n",
        "      U = array.array(\"f\")\n",
        "      U.frombytes(spec_data)\n",
        "      spec_dataS=\",\".join(map(str, U))\n",
        "      dfSS.loc[index,wvName] = spec_dataS\n",
        "#save the raw spectrum into file\n",
        "dfSS.to_csv(f'{path}{scalar}-spec-{nvcl_id}.csv', index=False, sep=',', encoding='utf-8')\n",
        "print(f'total specs:{len(dfSS)}')\n",
        "print(dfSS.head(5))\n"
      ],
      "metadata": {
        "id": "C4hG5ppxQFrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the spectrum chart\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "#load spectrum from file\n",
        "dfSS = pd.read_csv(f'{path}{scalar}-spec-{nvcl_id}.csv')\n",
        "#buildup wvLengths array from column name\n",
        "wv1 = dfSS.columns[-1]\n",
        "wv11 = wv1.split('-')\n",
        "wv1Start = float(wv11[1].replace('_','.'))\n",
        "wv1Step= float(wv11[2].replace('_','.'))\n",
        "wv1End = float(wv11[3].replace('_','.'))\n",
        "wv1Lengths = np.arange(wv1Start, wv1End+wv1Step,wv1Step,dtype=float)\n",
        "\n",
        "wv2 = dfSS.columns[-2]\n",
        "wv22 = wv2.split('-')\n",
        "wv2Start = float(wv22[1].replace('_','.'))\n",
        "wv2Step= float(wv22[2].replace('_','.'))\n",
        "wv2End = float(wv22[3].replace('_','.'))\n",
        "wv2Lengths = np.arange(wv2Start, wv2End+wv2Step,wv2Step,dtype=float)\n",
        "#init a empty dataframe\n",
        "cnames=['wvLengths']\n",
        "df1 = pd.DataFrame(columns=cnames)\n",
        "df1['wvLengths'] = wv1Lengths\n",
        "df2= pd.DataFrame(columns=cnames)\n",
        "df2['wvLengths'] = wv2Lengths\n",
        "#fillup the spec column into dataframe\n",
        "for index, row in dfSS.iterrows():\n",
        "  specName = f'spec{index}'\n",
        "  spec1 = np.array(row[wv1].split(','),dtype=np.float32)\n",
        "  spec2 = np.array(row[wv2].split(','),dtype=np.float32)\n",
        "  df1[specName] = spec1\n",
        "  df2[specName] = spec2\n",
        "\n",
        "#plot all specs\n",
        "fig,ax = plt.subplots()\n",
        "for col in df1.columns:\n",
        "  if col == 'wvLengths':\n",
        "    continue\n",
        "  ax.plot(df1['wvLengths'],df1[col],label=col)\n",
        "\n",
        "fig1,ax1 = plt.subplots()\n",
        "for col in df2.columns:\n",
        "  if col == 'wvLengths':\n",
        "    continue\n",
        "  ax1.plot(df2['wvLengths'],df2[col],label=col)\n",
        "\n"
      ],
      "metadata": {
        "id": "7DIVLQT873Ps"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeDr4fHdQHGCVr18Wu+I4U",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}